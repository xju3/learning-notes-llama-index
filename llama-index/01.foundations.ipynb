{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Global Environment Settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install llama-index-readers-smart-pdf-loader\n",
    "! pip install llama_index\n",
    "! pip install llmsherpa\n",
    "! pip install llama-index-readers-pdf-marker\n",
    "! pip install llama-index-readers-llama-parse\n",
    "! pip install llama-parse\n",
    "! pip install llama-index-storage-index-store-postgres\n",
    "! pip install llama-index-indices-managed-postgresml\n",
    "! pip install llama-index-storage-index-store-postgres\n",
    "! pip install llama-index-storage-docstore-postgres\n",
    "! pip install llama-index-storage-docstore-mongodb\n",
    "! pip install llama-index-storage-index-store-mongodb\n",
    "! pip install llama-index-llms-openai\n",
    "! pip install llama-index-extractors-entity\n",
    "! pip install llama-index-extractors-marvin\n",
    "! pip install unstructured\n",
    "! pip install lxml\n",
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```01.01✅.Set Application Runtime Environment```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from env import AppConfig\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import Settings\n",
    "load_dotenv(\".env\")\n",
    "mongo_uri = os.getenv(\"MONGO_URI\")\n",
    "pg_uri = os.getenv(\"PG_URI\")\n",
    "config = AppConfig()\n",
    "logger = config.logger\n",
    "llm = config.llm\n",
    "embedding = config.embedding\n",
    "# using ollama\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```01.02✅.Test if local llm is working```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(llm.complete(\"hi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```02.01✅.Read Documents 1: Using SimpleDirectoryReader   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.readers.file import (DocxReader, \n",
    "                                      HWPReader, \n",
    "                                      PDFReader, \n",
    "                                      EpubReader, \n",
    "                                      FlatReader, \n",
    "                                      HTMLTagReader, \n",
    "                                      ImageCaptionReader, \n",
    "                                      ImageReader, \n",
    "                                      ImageVisionLLMReader, \n",
    "                                      IPYNBReader, \n",
    "                                      MarkdownReader, \n",
    "                                      MboxReader, \n",
    "                                      PptxReader, \n",
    "                                      PandasCSVReader, \n",
    "                                      PandasExcelReader,\n",
    "                                      VideoAudioReader, \n",
    "                                      UnstructuredReader, \n",
    "                                      PyMuPDFReader, \n",
    "                                      ImageTabularChartReader, \n",
    "                                      XMLReader, \n",
    "                                      PagedCSVReader, \n",
    "                                      CSVReader, \n",
    "                                      RTFReader,)\n",
    "reader = SimpleDirectoryReader(\"./files\")\n",
    "docs = reader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```02.02✅.Read Documents 2: Using LlamaParse```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "from llama_index.readers.smart_pdf_loader import SmartPDFLoader\n",
    "from llama_index.readers.pdf_marker import PDFMarkerReader\n",
    "from pathlib import Path\n",
    "import numpy\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "parses = LlamaParse(\n",
    "    api_key=os.getenv(\"LLAMA_CLOUD_API_KEY\"),  # can also be set in your env as LLAMA_CLOUD_API_KEY\n",
    "    result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "document = parses.load_data(\"/Users/tju/Downloads/Books/1.pdf\")\n",
    "logger.debug(len(document))\n",
    "\n",
    "\n",
    "# ❌\n",
    "# llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
    "# pdf_url = \"https://arxiv.org/pdf/1910.13461.pdf\"  # also allowed is a file path e.g. /home/downloads/xyz.pdf\n",
    "# pdf_loader = SmartPDFLoader(llmsherpa_api_url=llmsherpa_api_url)\n",
    "# documents = pdf_loader.load_data(pdf_url)\n",
    "\n",
    "# ❌\n",
    "# path = Path(\"/Users/tju/Downloads/Books/1.pdf\")\n",
    "# reader = PDFMarkerReader()\n",
    "# document = reader.load_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```03.01✅.Using splitter to separate documents to chunks```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import (TokenTextSplitter, \n",
    "                                          MetadataAwareTextSplitter,\n",
    "                                          SentenceSplitter, \n",
    "                                          CodeSplitter)\n",
    "splitter = SentenceSplitter(chunk_size=1000, chunk_overlap=100, separator=\" \", include_prev_next_rel=True)\n",
    "nodes = splitter.get_nodes_from_documents(documents=docs)\n",
    "logger.debug(len(nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```03.02✅.Using Parser to separate documents to chunks```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import(SentenceWindowNodeParser, \n",
    "                                         SemanticDoubleMergingSplitterNodeParser, \n",
    "                                         SimpleFileNodeParser, \n",
    "                                         SemanticSplitterNodeParser,\n",
    "                                         NodeParser, \n",
    "                                         LlamaParseJsonNodeParser,\n",
    "                                         HTMLNodeParser, \n",
    "                                         JSONNodeParser, \n",
    "                                         SimpleNodeParser, \n",
    "                                         MarkdownNodeParser,\n",
    "                                         LangchainNodeParser, \n",
    "                                         HierarchicalNodeParser, \n",
    "                                         MarkdownElementNodeParser,\n",
    "                                         UnstructuredElementNodeParser)\n",
    "# has error message\n",
    "# parser = UnstructuredElementNodeParser()\n",
    "parser = SimpleFileNodeParser()\n",
    "nodes = parser.get_nodes_from_documents(documents=docs)\n",
    "logger.debug(len(nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```03.03✅.Using pipeline to seperate documents to chunks```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.extractors import TitleExtractor\n",
    "\n",
    "sentence_splitter = SentenceSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "title_extractor = TitleExtractor();\n",
    "transformations = [sentence_splitter, title_extractor, embedding]\n",
    "pipeline = IngestionPipeline( transformations = transformations)\n",
    "nodes = pipeline.run(documents=docs, num_workers=4)\n",
    "logger.debug(f\"nodes: {len(nodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```04.01✅.Extract meta-data 1: TitleExtractor  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.extractors import (\n",
    "    TitleExtractor, \n",
    "    SummaryExtractor, \n",
    "    KeywordExtractor,\n",
    "    PydanticProgramExtractor,\n",
    "    QuestionsAnsweredExtractor,)\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "title_extractor = TitleExtractor()\n",
    "title_meta_list = title_extractor.extract(nodes)\n",
    "\n",
    "for item in title_meta_list:\n",
    "    logger.debug(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```04.02✅.Extract meta-data 2: KeywordExtractor```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "keyword_extractor = TitleExtractor()\n",
    "keyword_meta_list = keyword_extractor.extract(nodes)\n",
    "for item in keyword_meta_list:\n",
    "    logger.debug(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```04.03❌.Extract meta-data : it needs huggingface api key.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.extractors.entity import EntityExtractor\n",
    "from llama_index.extractors.marvin import MarvinMetadataExtractor\n",
    "\n",
    "entity_extractor = EntityExtractor(model_name=\"your model name on huggingface\")\n",
    "entity_meta_list = entity_extractor.extract(nodes=nodes)\n",
    "for item in entity_meta_list:\n",
    "    logger.debug(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```05.01✅.Prepare Storage Context: Mongo```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.docstore.mongodb import MongoDocumentStore\n",
    "from llama_index.storage.index_store.mongodb import MongoIndexStore\n",
    "from llama_index.core import StorageContext\n",
    "mongo_storage_context = StorageContext.from_defaults(\n",
    "    docstore=MongoDocumentStore.from_uri(uri=mongo_uri),\n",
    "    index_store=MongoIndexStore.from_uri(uri=mongo_uri),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```05.02✅. Prepare Storage Context: Postgres```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.index_store.postgres import PostgresIndexStore\n",
    "from llama_index.storage.docstore.postgres import PostgresDocumentStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "pg_storage_context = StorageContext.from_defaults(\n",
    "    index_store=PostgresIndexStore.from_uri(uri=pg_uri),\n",
    "    docstore=PostgresDocumentStore.from_uri(uri=pg_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```06.01✅.Persist Chuncks```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_storage_context.docstore.add_documents(nodes)\n",
    "mongo_storage_context.docstore.add_documents(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```07.01✅.create document indices and persist indices```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (DocumentSummaryIndex, \n",
    "                              KeywordTableIndex, \n",
    "                              KnowledgeGraphIndex, \n",
    "                              PropertyGraphIndex,\n",
    "                              RAKEKeywordTableIndex,\n",
    "                              SimpleKeywordTableIndex,\n",
    "                              SummaryIndex, \n",
    "                              TreeIndex, \n",
    "                              VectorStoreIndex,\n",
    "                              ListIndex, \n",
    "                              GPTListIndex,\n",
    "                              GPTVectorStoreIndex,\n",
    "                              GPTTreeIndex,\n",
    "                              GPTSimpleKeywordTableIndex,)\n",
    "\n",
    "summary_index = SummaryIndex(nodes, storage_context=pg_storage_context)\n",
    "vector_index = VectorStoreIndex(nodes=nodes, embed_model=embedding, storage_context=pg_storage_context)\n",
    "simple_keyword_index = SimpleKeywordTableIndex(nodes=nodes, storage_context=pg_storage_context)\n",
    "pg_storage_context.persist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```07.02✅.Create Indices By ollama.ai, and persist data in online database.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.docstore.postgres import PostgresDocumentStore\n",
    "from llama_index.storage.kvstore.postgres import PostgresKVStore\n",
    "from llama_index.indices.managed.postgresml import PostgresMLIndex\n",
    "# conn_str = 'postgresql://llm:llm@192.168.1.3:5432/llm?sslmode=require'\n",
    "# kv_store = PostgresKVStore(connection_string=conn_str, async_connection_string=conn_str, table_name=\"pdf\",)\n",
    "# doc_store = PostgresDocumentStore(postgres_kvstore=kv_store)\n",
    "os.environ[\n",
    "    \"PGML_DATABASE_URL\"\n",
    "] = \"postgres://u_avmhinwq8sk1pgv:hktkhlft7grwzt5@437a9d42-c398-4c00-9906-c9b5fc2e7d61.gcp.db.postgresml.org:6432/pgml_7eqv4awesvjc0u9\"\n",
    "index = PostgresMLIndex.from_documents(collection_name= \"llama-index-test-1\", documents= document)\n",
    "# retriever = index.as_retriever()\n",
    "# results = retriever.retrieve(\"how many chapters in this book\")\n",
    "# logger.debug(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```08.01✅.Make query```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine()\n",
    "resp = query_engine.query(\"please give the document summary.\")\n",
    "logger.debug(resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
