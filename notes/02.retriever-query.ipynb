{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install llama_index\n",
    "! pip install llama-parse\n",
    "! pip install llmsherpa\n",
    "! pip install llama-index-readers-pdf-marker\n",
    "! pip install llama-index-readers-llama-parse\n",
    "! pip install llama-index-readers-smart-pdf-loader\n",
    "! pip install llama-index-indices-managed-postgresml\n",
    "! pip install llama-index-storage-index-store-postgres\n",
    "! pip install llama-index-storage-index-store-mongodb\n",
    "! pip install llama-index-storage-index-store-postgres\n",
    "! pip install llama-index-storage-docstore-postgres\n",
    "! pip install llama-index-storage-docstore-mongodb\n",
    "! pip install llama-index-vector-stores-postgres\n",
    "! pip install llama-index-vector-stores-pinecone\n",
    "! pip install llama-index-vector-stores-chroma\n",
    "! pip install llama-index-llms-openai\n",
    "! pip install llama-index-llms-ollama\n",
    "! pip install llama-index-extractors-entity\n",
    "! pip install llama-index-extractors-marvin\n",
    "! pip install unstructured\n",
    "! pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import AppConfig\n",
    "from llama_index.core import Settings\n",
    "config = AppConfig()\n",
    "logger = config.logger\n",
    "# resp = Settings.llm.complete(\"hello\")\n",
    "# config.logger.debug(resp)\n",
    "question = 'who comes from Lawrence Berkely National Labatorry in this book'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```01.01. laod vector index from database ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "from llama_index.core import Settings, VectorStoreIndex\n",
    "from sqlalchemy import make_url\n",
    "url = make_url(config.pg_uri)\n",
    "pg_vec_store = PGVectorStore.from_params(\n",
    "    database=url.database, \n",
    "    host=url.host, \n",
    "    password=url.password, \n",
    "    port=url.port, \n",
    "    user=url.username, \n",
    "    table_name=\"vec_store\", \n",
    "    embed_dim=4096,  # openai embedding dimension \n",
    "    hnsw_kwargs={\n",
    "            \"hnsw_m\": 16,\n",
    "            \"hnsw_ef_construction\": 64,\n",
    "            \"hnsw_ef_search\": 40,\n",
    "            \"hnsw_dist_method\": \"vector_cosine_ops\",\n",
    "        })\n",
    "idx = VectorStoreIndex.from_vector_store(vector_store=pg_vec_store, embed_model=Settings.embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```01.02 define meter-filters ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores.types import (FilterOperator, \n",
    "                                                  FilterCondition, \n",
    "                                                  MetadataFilter, \n",
    "                                                  MetadataFilters) \n",
    "\n",
    "filters = MetadataFilters(\n",
    "    filters=[MetadataFilter(key=\"department\",  value=\"Procurement\"  ),\n",
    "             MetadataFilter(key=\"security_classification\",  value='',  operator=FilterOperator.LTE)],  \n",
    "    condition=FilterCondition.AND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```01.03. Define Selectors ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.selectors import (LLMMultiSelector, \n",
    "                                        PydanticMultiSelector,\n",
    "                                        LLMSingleSelector)\n",
    "options = [\n",
    "    \"option 1: this is good for summarization questions\",  \n",
    "    \"option 2: this is useful for precise definitions\",  \n",
    "    \"option 3: this is useful for comparing concepts\",]\n",
    "selector = LLMSingleSelector.from_defaults() \n",
    "selections = selector.select(options,  \n",
    "                           query=\"What's the definition of space?\"  )\n",
    "logger.debug(type(selections))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```01.04.Retrievers```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import (AutoMergingRetriever, \n",
    "                                         BaseRetriever,\n",
    "                                         BaseImageRetriever, \n",
    "                                         EmptyIndexRetriever, \n",
    "                                         KeywordTableSimpleRetriever,\n",
    "                                         KGTableRetriever, \n",
    "                                         KnowledgeGraphRAGRetriever,\n",
    "                                         LLMSynonymRetriever, ListIndexRetriever,\n",
    "                                         RecursiveRetriever,\n",
    "                                         RouterRetriever,\n",
    "                                         TextToCypherRetriever,\n",
    "                                         TransformRetriever,\n",
    "                                         TreeRootRetriever,\n",
    "                                         TreeSelectLeafRetriever,\n",
    "                                         TreeSelectLeafEmbeddingRetriever,\n",
    "                                         SummaryIndexEmbeddingRetriever, \n",
    "                                         SummaryIndexLLMRetriever,\n",
    "                                         SummaryIndexRetriever,\n",
    "                                         VectorIndexRetriever,\n",
    "                                         VectorContextRetriever,\n",
    "                                         VectorIndexAutoRetriever,\n",
    "                                         )\n",
    "from llama_index.core.vector_stores.types import VectorStoreQueryMode\n",
    "\n",
    "retriever = VectorIndexRetriever(index=idx, \n",
    "                                 vector_store_query_mode=VectorStoreQueryMode.DEFAULT, \n",
    "                                 embed_model=Settings.embed_model, \n",
    "                                 filters=[],\n",
    "                                 callback_manager=None,\n",
    "                                 alpha=0.9,\n",
    "                                 verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```01.05.Define Tools ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import RetrieverTool\n",
    "vector_tool = RetrieverTool.from_defaults(retriever=retriever, description=\"....\")\n",
    "\n",
    "router_retriever = RouterRetriever(selector=selector,\n",
    "                                   retriever_tools=[vector_tool], llm=Settings.llm)\n",
    "resp = router_retriever.retrieve(\"Xiangyang\")\n",
    "logger.debug(type(resp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```01.06. DecomposeQueryTransform```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.query.query_transform.base import  DecomposeQueryTransform  \n",
    "decompose = DecomposeQueryTransform(llm=Settings.llm,)  \n",
    "query_bundle = decompose.run(\"Who comes from Lawrence Berkeley National Labaratory and when did the LBNL established\") \n",
    "logger.debug(f'bundle: {query_bundle.query_str}')\n",
    "query_engine = idx.as_query_engine()\n",
    "resp = query_engine.query(query_bundle.query_str)\n",
    "logger.debug(resp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```01.07. OpenAIQuestionGenerator ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```02.00 Postprocessors```\n",
    "- Node Filtering Postprocessors\n",
    "- Node Transforming Postprocessors\n",
    "- Node Re-Ranking Postprocessors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```02.01. Postprocessors```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import (AutoPrevNextNodePostprocessor, \n",
    "                                            EmbeddingRecencyPostprocessor,\n",
    "                                            FixedRecencyPostprocessor,\n",
    "                                            KeywordNodePostprocessor,\n",
    "                                            MetadataReplacementPostProcessor,\n",
    "                                            NERPIINodePostprocessor,\n",
    "                                            PrevNextNodePostprocessor, \n",
    "                                            PIINodePostprocessor, \n",
    "                                            SimilarityPostprocessor,\n",
    "                                            TimeWeightedPostprocessor,)\n",
    "original_nodes = retriever.retrieve(question)\n",
    "pp =SimilarityPostprocessor(similarity_cutoff=0.8)\n",
    "remaining_nodes = pp.postprocess_nodes(original_nodes)\n",
    "for node in remaining_nodes:\n",
    "    logger.debug(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
