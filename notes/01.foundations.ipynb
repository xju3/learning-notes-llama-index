{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.0.Pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install llama_index\n",
    "! pip install llama-parse\n",
    "! pip install llmsherpa\n",
    "! pip install llama-index-readers-pdf-marker\n",
    "! pip install llama-index-readers-llama-parse\n",
    "! pip install llama-index-readers-smart-pdf-loader\n",
    "! pip install llama-index-indices-managed-postgresml\n",
    "! pip install llama-index-storage-index-store-postgres\n",
    "! pip install llama-index-storage-index-store-mongodb\n",
    "! pip install llama-index-storage-index-store-postgres\n",
    "! pip install llama-index-storage-docstore-postgres\n",
    "! pip install llama-index-storage-docstore-mongodb\n",
    "! pip install llama-index-vector-stores-postgres\n",
    "! pip install llama-index-vector-stores-pinecone\n",
    "! pip install llama-index-vector-stores-mongodb\n",
    "! pip install llama-index-vector-stores-chroma\n",
    "! pip install llama-index-vector-stores-redis\n",
    "! pip install llama-index-embeddings-huggingface\n",
    "! pip install llama-index-embeddings-instructor\n",
    "! pip install llama-index-llms-openai\n",
    "! pip install llama-index-llms-ollama\n",
    "! pip install llama-index-extractors-entity\n",
    "! pip install llama-index-extractors-marvin\n",
    "! pip install unstructured\n",
    "! pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0.Set Application Runtime Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.Initialize AppConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from llama_index.core import Settings\n",
    "from common.env import AppConfig\n",
    "\n",
    "config = AppConfig()\n",
    "logger = config.logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.Test if local llm is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(config.llm.complete(\"你好\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 Using File or Directory Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.Reading documents using SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.readers.file import (DocxReader, \n",
    "                                      HWPReader, \n",
    "                                      PDFReader, \n",
    "                                      EpubReader, \n",
    "                                      FlatReader, \n",
    "                                      HTMLTagReader, \n",
    "                                      ImageCaptionReader, \n",
    "                                      ImageReader, \n",
    "                                      ImageVisionLLMReader, \n",
    "                                      IPYNBReader, \n",
    "                                      MarkdownReader, \n",
    "                                      MboxReader, \n",
    "                                      PptxReader, \n",
    "                                      PandasCSVReader, \n",
    "                                      PandasExcelReader,\n",
    "                                      VideoAudioReader, \n",
    "                                      UnstructuredReader, \n",
    "                                      PyMuPDFReader, \n",
    "                                      ImageTabularChartReader, \n",
    "                                      XMLReader, \n",
    "                                      PagedCSVReader, \n",
    "                                      CSVReader, \n",
    "                                      RTFReader,)\n",
    "reader = SimpleDirectoryReader(\"./pdf_files\")\n",
    "docs = reader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.Read Documents 2: Using LlamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "from llama_index.readers.smart_pdf_loader import SmartPDFLoader\n",
    "from llama_index.readers.pdf_marker import PDFMarkerReader\n",
    "from pathlib import Path\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "parses = LlamaParse(\n",
    "    api_key=os.getenv(\"LLAMA_CLOUD_API_KEY\"),  # can also be set in your env as LLAMA_CLOUD_API_KEY\n",
    "    result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "docs = parses.load_data(f\"{Path.cwd()}/pdf_files/2407.21290v1.pdf\")\n",
    "logger.debug(len(docs))\n",
    "\n",
    "\n",
    "# ❌\n",
    "# llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
    "# pdf_url = \"https://arxiv.org/pdf/1910.13461.pdf\"  # also allowed is a file path e.g. /home/downloads/xyz.pdf\n",
    "# pdf_loader = SmartPDFLoader(llmsherpa_api_url=llmsherpa_api_url)\n",
    "# documents = pdf_loader.load_data(pdf_url)\n",
    "\n",
    "# ❌\n",
    "# path = Path(\"/Users/tju/Downloads/Books/1.pdf\")\n",
    "# reader = PDFMarkerReader()\n",
    "# document = reader.load_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0. Using Splitter, Parse, Pipepine to Separate Documents to Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import (TokenTextSplitter, \n",
    "                                          MetadataAwareTextSplitter,\n",
    "                                          SentenceSplitter, \n",
    "                                          CodeSplitter)\n",
    "splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=128, separator=\" \", include_prev_next_rel=True)\n",
    "nodes = splitter.get_nodes_from_documents(documents=docs)\n",
    "logger.debug(len(nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.Using Parser to separate documents to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import(SentenceWindowNodeParser, \n",
    "                                         SemanticDoubleMergingSplitterNodeParser, \n",
    "                                         SimpleFileNodeParser, \n",
    "                                         SemanticSplitterNodeParser,\n",
    "                                         NodeParser, \n",
    "                                         LlamaParseJsonNodeParser,\n",
    "                                         HTMLNodeParser, \n",
    "                                         JSONNodeParser, \n",
    "                                         SimpleNodeParser, \n",
    "                                         MarkdownNodeParser,\n",
    "                                         LangchainNodeParser, \n",
    "                                         HierarchicalNodeParser, \n",
    "                                         MarkdownElementNodeParser,\n",
    "                                         UnstructuredElementNodeParser)\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "sentence_splitter = SentenceSplitter()\n",
    "# has error message\n",
    "# parser = UnstructuredElementNodeParser()\n",
    "# parser = SimpleFileNodeParser()\n",
    "parser = SemanticSplitterNodeParser.from_defaults(embed_model=Settings.embed_model)\n",
    "# parser = SentenceWindowNodeParser.from_defaults(window_size=2, window_metadata_key=\"text_window\", original_text_metadata_key='original_sentence')\n",
    "nodes = parser.build_semantic_nodes_from_documents(docs)\n",
    "logger.debug(len(nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.0.Using Extractor to Refine meta_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.TitleExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "keyword_extractor = TitleExtractor()\n",
    "keyword_meta_list = keyword_extractor.extract(nodes)\n",
    "for item in keyword_meta_list:\n",
    "    logger.debug(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.KeywordExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "title_extractor = TitleExtractor()\n",
    "keyword_meta_list = keyword_extractor.extract(nodes=nodes)\n",
    "for item in keyword_meta_list:\n",
    "    logger.debug(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.Entity Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.extractors.entity import EntityExtractor\n",
    "from llama_index.extractors.marvin import MarvinMetadataExtractor\n",
    "\n",
    "entity_extractor = EntityExtractor(device=\"cpu\", label_entities=True)\n",
    "entity_meta_list = entity_extractor.extract(nodes=nodes)\n",
    "for item in entity_meta_list:\n",
    "    logger.debug(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4. using pipepine to ingest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import TokenTextSplitter, SentenceSplitter\n",
    "from llama_index.core.extractors import TitleExtractor, KeywordExtractor\n",
    "\n",
    "token_text_splitter = TokenTextSplitter(include_prev_next_rel=True)\n",
    "sentence_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=20, include_prev_next_rel=True)\n",
    "title_extractor = TitleExtractor()\n",
    "keyword_extractor = KeywordExtractor()\n",
    "# entity_extractor = EntityExtractor(device=\"cpu\", label_entities=True)\n",
    "transformations = [sentence_splitter, title_extractor, keyword_extractor, config.embedding]\n",
    "pipeline = IngestionPipeline(transformations = transformations,)\n",
    "nodes = pipeline.run(documents=docs, num_workers=8,)\n",
    "logger.debug(f\"nodes: {len(nodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5. Test Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import  VectorStoreIndex\n",
    "# index = VectorStoreIndex.from_documents(docs)\n",
    "index = VectorStoreIndex(nodes=nodes, embed_model=Settings.embed_model)\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "# resp = query_engine.query(\"林斌是谁\")\n",
    "# resp = query_engine.query(\"林斌是哪年出生的\")\n",
    "resp = query_engine.query(\"文档内容中提到哪家会计师事务所\")\n",
    "# resp = query_engine.query('详细介绍一下文件中的林斌')\n",
    "# resp = query_engine.query('林斌的教育背景')\n",
    "# resp = query_engine.query('林斌有硕士学历吗')\n",
    "# resp = query_engine.query('林斌本科毕业于哪所大学')\n",
    "logger.debug(resp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0 Preparing Store Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.docstore.mongodb import MongoDocumentStore\n",
    "from llama_index.storage.index_store.mongodb import MongoIndexStore\n",
    "from llama_index.core import StorageContext\n",
    "mongo_storage_context = StorageContext.from_defaults(\n",
    "    docstore=MongoDocumentStore.from_uri(uri=config.mongo_uri),\n",
    "    index_store=MongoIndexStore.from_uri(uri=config.mongo_uri),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.[postgresql](pg.sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.index_store.postgres import PostgresIndexStore\n",
    "from llama_index.storage.docstore.postgres import PostgresDocumentStore\n",
    "from llama_index.storage.kvstore.postgres import PostgresKVStore\n",
    "from llama_index.vector_stores.postgres.base import PGVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from sqlalchemy import make_url\n",
    "url = make_url(config.pg_uri)\n",
    "logger.debug(url)\n",
    "db_schema='qwen'\n",
    "\n",
    "pg_doc_store = PostgresDocumentStore.from_uri(uri=config.pg_uri, \n",
    "                                              table_name='doc_store', \n",
    "                                              schema_name=db_schema)\n",
    "\n",
    "pg_idx_store = PostgresIndexStore.from_uri(uri=config.pg_uri, \n",
    "                                           table_name='idx_store', \n",
    "                                           schema_name=db_schema)\n",
    "\n",
    "pg_vec_store = PGVectorStore.from_params(database=url.database, \n",
    "                                         host=url.host, \n",
    "                                         port=url.port, \n",
    "                                         password=url.password, \n",
    "                                         user=url.username, \n",
    "                                         schema_name=db_schema, \n",
    "                                         table_name=\"vec_store_3584\", \n",
    "                                         embed_dim=3584,  # openai embedding dimension \n",
    "                                         hnsw_kwargs = {\n",
    "                                            \"hnsw_m\": 16,\n",
    "                                            \"hnsw_ef_construction\": 64,\n",
    "                                            \"hnsw_ef_search\": 40,\n",
    "                                            \"hnsw_dist_method\": \"vector_cosine_ops\",\n",
    "                                         },\n",
    "    )\n",
    "pg_storage_context = StorageContext.from_defaults(index_store=pg_idx_store, \n",
    "                                                  docstore=pg_doc_store, \n",
    "                                                  vector_store=pg_vec_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.0.Persist Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1.Persist Chuncks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_storage_context.docstore.add_documents(docs=docs)\n",
    "# mongo_storage_context.docstore.add_documents(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2. Persist Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (DocumentSummaryIndex, \n",
    "                              KeywordTableIndex, \n",
    "                              KnowledgeGraphIndex, \n",
    "                              PropertyGraphIndex,\n",
    "                              RAKEKeywordTableIndex,\n",
    "                              SimpleKeywordTableIndex,\n",
    "                              SummaryIndex, \n",
    "                              TreeIndex, \n",
    "                              VectorStoreIndex,\n",
    "                              ListIndex, \n",
    "                              GPTListIndex,\n",
    "                              GPTVectorStoreIndex,\n",
    "                              GPTTreeIndex,\n",
    "                              GPTSimpleKeywordTableIndex,)\n",
    "\n",
    "# summary_index = SummaryIndex(nodes, storage_context=pg_storage_context)\n",
    "vector_index = VectorStoreIndex(nodes=nodes, embed_model=config.embedding, storage_context=pg_storage_context)\n",
    "# simple_keyword_index = SimpleKeywordTableIndex(nodes=nodes, storage_context=pg_storage_context)\n",
    "# pg_storage_context.index_store.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 06.03.Create Indices By ollama.ai, and persist data in online database.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.docstore.postgres import PostgresDocumentStore\n",
    "from llama_index.storage.kvstore.postgres import PostgresKVStore\n",
    "from llama_index.indices.managed.postgresml import PostgresMLIndex\n",
    "# conn_str = 'postgresql://llm:llm@192.168.1.3:5432/llm?sslmode=require'\n",
    "# kv_store = PostgresKVStore(connection_string=conn_str, async_connection_string=conn_str, table_name=\"pdf\",)\n",
    "# doc_store = PostgresDocumentStore(postgres_kvstore=kv_store)\n",
    "index = PostgresMLIndex.from_documents(collection_name= \"llama-index-test-1\", documents= docs)\n",
    "# retriever = index.as_retriever()\n",
    "# results = retriever.retrieve(\"how many chapters in this book\")\n",
    "# logger.debug(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
